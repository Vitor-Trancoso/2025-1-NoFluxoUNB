name: Run web scraper

on:
  push:
    branches: [main]
  workflow_dispatch:
  schedule:
    - cron: '0 0 1 * *'  # Executa às 00:00 do dia 1 de cada mês 

jobs:
     build:
        runs-on: ubuntu-latest
        steps:

          - name: Checkout Repository
            uses: actions/checkout@v3
          
          - name: Setup Python
            uses: actions/setup-python@v4
            with:
              python-version: '3.9'

          - name: Upgrade pip and install Cython
            run: |
              python -m pip install --upgrade pip
              pip install Cython

          - name: Install dependencies
            run: |
              pip install wheel
              pip install --no-build-isolation -r coleta_dados/scraping/requirements.txt

          - name: Execute Script
            run:
              python coleta_dados/scraping/scraping_ementa.py
              python coleta_dados/scraping/extrair_turmas_sigaa.py
              python coleta_dados/scraping/executar_fluxo_dados_RAGFLOW.py
              python coleta_dados/scraping/formatar_para_ragflow.py
              python coleta_dados/scraping/scraping_ementa.py
              
              

          - name: Commit Changes
            uses: stefanzweifel/git-auto-commit-action@v4
            with:
              commit_message: "[CI] Relatórios encontrados e baixados com sucesso!"
              file_pattern: "dados/estruturas-curriculares/*.json"
